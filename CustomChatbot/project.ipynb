{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "124e5672",
   "metadata": {},
   "source": [
    "# Custom Chatbot Project"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a4a94b3",
   "metadata": {},
   "source": [
    "TODO: In this cell, write an explanation of which dataset you have chosen and why it is appropriate for this task"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a63d4c5f",
   "metadata": {},
   "source": [
    "## Data Wrangling\n",
    "\n",
    "TODO: In the cells below, load your chosen dataset into a `pandas` dataframe with a column named `\"text\"`. This column should contain all of your text data, separated into at least 20 rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c69b83a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a595980",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load dataframe\n",
    "df = pd.read_csv(\"data/2023_fashion_trends.csv\")\n",
    "\n",
    "# check first rows\n",
    "df.head()\n",
    "\n",
    "# get rid of url and source\n",
    "df.drop([\"URL\", \"Source\"], axis=1, inplace=True)\n",
    "\n",
    "# replace trends with text\n",
    "df = df.rename(columns={\"Trends\": \"text\"})\n",
    "\n",
    "# check first rows\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acb3a9fd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ae769871",
   "metadata": {},
   "source": [
    "## Custom Query Completion\n",
    "\n",
    "TODO: In the cells below, compose a custom query using your chosen dataset and retrieve results from an OpenAI `Completion` model. You may copy and paste any useful code from the course materials."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "582f0656",
   "metadata": {},
   "outputs": [],
   "source": [
    "#openai.api_base = \"https://openai.vocareum.com/v1\"\n",
    "#openai.api_key = \"voc-112508657912667737229736767e1efdeb6e1.78861005\" #\"YOUR API KEY\"\n",
    "\n",
    "openai.api_base = \"https://api.openai.com/v1\"\n",
    "openai.api_key = \"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\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b6e1f75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up variables for model and max tokens\n",
    "COMPLETION_MODEL_NAME = \"gpt-3.5-turbo-instruct\"\n",
    "MAX_TOKENS = 2400"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13f2dcd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#prepare embeddings\n",
    "EMBEDDING_MODEL_NAME = \"text-embedding-ada-002\"\n",
    "batch_size = 25\n",
    "embeddings = []\n",
    "for i in range(0, len(df), batch_size):\n",
    "    # Send text data to OpenAI model to get embeddings\n",
    "    response = openai.Embedding.create(\n",
    "        input=df.iloc[i:i+batch_size][\"text\"].tolist(),\n",
    "        engine=EMBEDDING_MODEL_NAME\n",
    "    )\n",
    "    \n",
    "    # Add embeddings to list\n",
    "    embeddings.extend([data[\"embedding\"] for data in response[\"data\"]])\n",
    "\n",
    "\n",
    "\n",
    "# Add embeddings list to dataframe\n",
    "df[\"embeddings\"] = embeddings\n",
    "# check cotent and embeddigins\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c403f543",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create simple prompt\n",
    "def create_simple_prompt(question):\n",
    "   \n",
    "    prompt_template = \"\"\"\n",
    "Question: {}\n",
    "Answer:\"\"\"\n",
    "    \n",
    "    return prompt_template.format(\"\\n\\n###\\n\\n\", question)\n",
    "    \n",
    "# define how to answer to a prompt\n",
    "def answer_prompt(\n",
    "    prompt, df, max_answer_tokens=150\n",
    "):\n",
    "   \n",
    "    \n",
    "    try:\n",
    "        response = openai.Completion.create(\n",
    "            model=COMPLETION_MODEL_NAME,\n",
    "            prompt=prompt,\n",
    "            max_tokens=max_answer_tokens\n",
    "        )\n",
    "        return response[\"choices\"][0][\"text\"].strip()\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        return \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74280b92",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai.embeddings_utils import get_embedding, distances_from_embeddings\n",
    "\n",
    "def get_rows_sorted_by_relevance(question, df):\n",
    "    \"\"\"\n",
    "    Function that takes in a question string and a dataframe containing\n",
    "    rows of text and associated embeddings, and returns that dataframe\n",
    "    sorted from least to most relevant for that question\n",
    "    \"\"\"\n",
    "    \n",
    "    # Get embeddings for the question text\n",
    "    question_embeddings = get_embedding(question, engine=EMBEDDING_MODEL_NAME)\n",
    "    \n",
    "    # Make a copy of the dataframe and add a \"distances\" column containing\n",
    "    # the cosine distances between each row's embeddings and the\n",
    "    # embeddings of the question\n",
    "    df_copy = df.copy()\n",
    "    df_copy[\"distances\"] = distances_from_embeddings(\n",
    "        question_embeddings,\n",
    "        df_copy[\"embeddings\"].values,\n",
    "        distance_metric=\"cosine\"\n",
    "    )\n",
    "    \n",
    "    # Sort the copied dataframe by the distances and return it\n",
    "    # (shorter distance = more relevant so we sort in ascending order)\n",
    "    df_copy.sort_values(\"distances\", ascending=True, inplace=True)\n",
    "    return df_copy\n",
    "\n",
    "import tiktoken\n",
    "\n",
    "def create_RAG_prompt(question, df, max_token_count):\n",
    "    \"\"\"\n",
    "    Given a question and a dataframe containing rows of text and their\n",
    "    embeddings, return a text prompt to send to a Completion model\n",
    "    \"\"\"\n",
    "    # Create a tokenizer that is designed to align with our embeddings\n",
    "    tokenizer = tiktoken.get_encoding(\"cl100k_base\")\n",
    "    \n",
    "    # Count the number of tokens in the prompt template and question\n",
    "    prompt_template = \"\"\"\n",
    "Answer the question based on the context below, and if the question\n",
    "can't be answered based on the context, say \"I don't know\"\n",
    "\n",
    "Context: \n",
    "\n",
    "{}\n",
    "\n",
    "---\n",
    "\n",
    "Question: {}\n",
    "Answer:\"\"\"\n",
    "    \n",
    "    current_token_count = len(tokenizer.encode(prompt_template)) + \\\n",
    "                            len(tokenizer.encode(question))\n",
    "    \n",
    "    context = []\n",
    "    for text in get_rows_sorted_by_relevance(question, df)[\"text\"].values:\n",
    "        \n",
    "        # Increase the counter based on the number of tokens in this row\n",
    "        text_token_count = len(tokenizer.encode(text))\n",
    "        current_token_count += text_token_count\n",
    "        \n",
    "        # Add the row of text to the list if we haven't exceeded the max\n",
    "        if current_token_count <= max_token_count:\n",
    "            context.append(text)\n",
    "        else:\n",
    "            break\n",
    "\n",
    "    return prompt_template.format(\"\\n\\n###\\n\\n\".join(context), question)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1783f146",
   "metadata": {},
   "source": [
    "## Custom Performance Demonstration\n",
    "\n",
    "TODO: In the cells below, demonstrate the performance of your custom query using at least 2 questions. For each question, show the answer from a basic `Completion` model query as well as the answer from your custom query."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f11fdc0",
   "metadata": {},
   "source": [
    "### Question 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4901c850",
   "metadata": {},
   "outputs": [],
   "source": [
    "q1 = \"What are the fashion trends on 2023?\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd7a093b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Print answer without RAG\n",
    "print('\\nQ1: Answer without RAG: \\n', answer_prompt(create_simple_prompt(q1), df))\n",
    "print('\\nQ1: Answer with RAG: \\n', answer_prompt(create_RAG_prompt(q1, df, 2000), df))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e86e37c",
   "metadata": {},
   "source": [
    "### Question 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f646989",
   "metadata": {},
   "outputs": [],
   "source": [
    "q2 = \"Which are the most popular colors for 2023?\"\n",
    "\n",
    "print('\\nQ2: Answer without RAG: \\n', answer_prompt(create_simple_prompt(q2), df))\n",
    "print('\\nQ2: Answer with RAG: \\n', answer_prompt(create_RAG_prompt(q2, df, 2000), df))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11c07a54",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a8a6095",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel) y",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
